{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"data/music_genre.csv\", index_col=0)\n",
    "\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data description\n",
    "\n",
    "- instance_id - id of a song\n",
    "- artist_name - the name of the artist\n",
    "- track_name - the name of the song\n",
    "- popularity - value between 0 and 100, with 100 being the most popular. The popularity is calculated by algorithm and is   based, in the most part, on the total number of plays the track has had and how recent those plays are.\n",
    "- acousticness - a confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n",
    "- danceability - a value between 0.0 and 1.0 of how suitable the track is for dancing\n",
    "- duration_ms - duration of a track in milliseconds\n",
    "- energy - a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity.\n",
    "- instrumentalness - The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content.\n",
    "- key - the key of the track (C, C# ... B)\n",
    "- liveness - Detects the presence of an audience in the recording. Form 0.0 to 1.0\n",
    "- loudness - measure of how loud the track is. From -60 (silence) to 0 (max loudness without distortion)\n",
    "- mode - mode of the track (Minor, Major)\n",
    "- speechiness - detects the presence of spoken words in a track.\n",
    "- tempo - tempo of the song in bpm\n",
    "- obtained_date - date\n",
    "- valence - A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track.\n",
    "- music_genre - genre of the track (target)\n",
    "\n",
    "more info -> https://developer.spotify.com/documentation/web-api/reference/get-audio-features\n",
    "\n"
   ],
   "id": "1a542905856dfcec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Removing the missing values\n",
    "\n",
    "we have so much rows that we are just going to drop the ones with missing values"
   ],
   "id": "9f28dc7397baced9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "in the artist_name they are denoted as 'empty_field'",
   "id": "df60e8dedb9aaaec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df['artist_name'] == 'empty_field']",
   "id": "2ab84798c81ce24f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "in the tempo they are denoted as '?'",
   "id": "df4e3506638d7c1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df['tempo'] == '?']",
   "id": "5e1bfe8dac1d6ebb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['artist_name'] = df['artist_name'].replace('empty_field', np.nan)\n",
    "df['tempo'] = df['tempo'].replace('?', np.nan)\n",
    "\n",
    "df.dropna(inplace=True)"
   ],
   "id": "baa239a0759ca1c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "some songs have the duration of -1 ms so lets use IterativeImputer to fill in the blanks",
   "id": "ab911fd440d2240a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "df['duration_ms'] = df['duration_ms'].replace(-1,np.nan)\n",
    "\n",
    "imputer = IterativeImputer(estimator=BayesianRidge(), random_state=42)\n",
    "\n",
    "df['duration_ms'] = imputer.fit_transform(df[['duration_ms']])\n",
    "\n",
    "df"
   ],
   "id": "6e18d1cb04848a97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dropping the obtained_date",
   "id": "4789c1809e0f61ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.drop('obtained_date', inplace=True, axis=1)\n",
    "\n",
    "df"
   ],
   "id": "d96c60d1bfb001f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "and finally change the tempo into a float",
   "id": "901f69abb6224c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['tempo'] = df['tempo'].apply(lambda x: float(x))\n",
    "\n",
    "df"
   ],
   "id": "1b9dc43c4b14f51a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Summary of some columns",
   "id": "126295b7d58a233f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical = df.select_dtypes(exclude=object).columns\n",
    "categorical = df.select_dtypes(include=object).columns\n",
    "\n",
    "print(numerical)\n",
    "print(categorical)"
   ],
   "id": "f9733e99656ddefe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[numerical].describe()",
   "id": "44607634df276a79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[categorical].describe()",
   "id": "fc95e87ce3e227d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def df_proportions(name):\n",
    "    return df[name].value_counts(normalize=True).sort_values(ascending=False)\n",
    "\n",
    "df_proportions('artist_name')"
   ],
   "id": "a3f432e15990e8b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_proportions('track_name')",
   "id": "53656f86ee665b83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_proportions('key')",
   "id": "5e1e87a21d3b163a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_proportions('music_genre')",
   "id": "bc35e4f3bc978075",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "numerical",
   "id": "998d1dd285d4031f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data visualization",
   "id": "17ea972832eaf55b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for col in numerical:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    sns.boxplot(x='music_genre', y=col, data=df)\n",
    "    plt.show()"
   ],
   "id": "725bec69786d99a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for col in numerical:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    sns.violinplot(x='music_genre', y=col, data=df)\n",
    "    plt.show()"
   ],
   "id": "7a00f26797ffb095",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Emotional Characteristics of Musical Keys\n",
    "\n",
    "## C\n",
    "\n",
    "- **C Major** – Innocently Happy\n",
    "- **C Minor** – Innocently Sad, Love-Sick\n",
    "\n",
    "## C♯ / D♭\n",
    "\n",
    "- **C♯ Minor** – Despair, Wailing, Weeping\n",
    "- **D♭ Major** – Grief, Depressive\n",
    "\n",
    "## D\n",
    "\n",
    "- **D Major** – Triumphant, Victorious War-Cries\n",
    "- **D Minor** – Serious, Pious, Ruminating\n",
    "\n",
    "## D♯ / E♭\n",
    "\n",
    "- **D♯ Minor** – Deep Distress, Existential Angst\n",
    "- **E♭ Major** – Cruel, Hard, Yet Full of Devotion\n",
    "\n",
    "## E\n",
    "\n",
    "- **E Major** – Quarrelsome, Boisterous, Incomplete Pleasure\n",
    "- **E Minor** – Effeminate, Amorous, Restless\n",
    "\n",
    "## F\n",
    "\n",
    "- **F Major** – Furious, Quick-Tempered, Passing Regret\n",
    "- **F Minor** – Obscure, Plaintive, Funereal\n",
    "\n",
    "## F♯ / G♭\n",
    "\n",
    "- **F♯ Major** – Conquering Difficulties, Sighs of Relief\n",
    "- **F♯ Minor** – Gloomy, Passionate Resentment\n",
    "\n",
    "## G\n",
    "\n",
    "- **G Major** – Serious, Magnificent, Fantasy\n",
    "- **G Minor** – Discontent, Uneasiness\n",
    "\n",
    "## A♭\n",
    "\n",
    "- **A♭ Major** – Death, Eternity, Judgement\n",
    "- **A♭ Minor** – Grumbling, Moaning, Wailing\n",
    "\n",
    "## A\n",
    "\n",
    "- **A Major** – Joyful, Pastoral, Declaration of Love\n",
    "- **A Minor** – Tender, Plaintive, Pious\n",
    "\n",
    "## B♭\n",
    "\n",
    "- **B♭ Major** – Joyful, Quaint, Cheerful\n",
    "- **B♭ Minor** – Terrible, the Night, Mocking\n",
    "\n",
    "## B\n",
    "\n",
    "- **B Major** – Harsh, Strong, Wild, Rage\n",
    "- **B Minor** – Solitary, Melancholic, Patience\n"
   ],
   "id": "df2d1845a2baf464"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genres = df['music_genre'].unique()\n",
    "\n",
    "mode_palette = {\n",
    "    'Minor': 'blue',\n",
    "    'Major': 'orange'\n",
    "}\n",
    "\n",
    "keys_order = df['key'].unique()\n",
    "keys_order.sort()\n",
    "\n",
    "for genre in genres:\n",
    "    subset = df[df['music_genre'] == genre]\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    sns.countplot(data=subset,x='key',hue='mode', palette=mode_palette, order=keys_order)\n",
    "    plt.title(genre)\n",
    "    plt.show()"
   ],
   "id": "2893ac618d439afe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(data=df, x='key',hue='mode', palette=mode_palette, order=keys_order)\n",
    "plt.title(\"Keys-mode hist\")\n",
    "plt.show()"
   ],
   "id": "6123470ab72543ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Major mode dominates the histogram",
   "id": "e68e0ac216dcbf16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.hist(figsize=(12,12), bins=20)",
   "id": "70ed2c4e5104f542",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "More of the saddest songs than the happiest songs",
   "id": "7b5b91799a3eb213"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "bdc3f6bbeb2e7182",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Encoding categorical (except artist_name adn track_name)",
   "id": "c22574fbf0bb0f59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_keys = LabelEncoder()\n",
    "\n",
    "df['key'] = le_keys.fit_transform(df['key'])\n",
    "\n",
    "df"
   ],
   "id": "317d3bc7e20361c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mode_encoding = {\n",
    "    'Minor': 0,\n",
    "    'Major': 1\n",
    "}\n",
    "\n",
    "df['mode'] = df['mode'].map(mode_encoding)\n",
    "\n",
    "df"
   ],
   "id": "2761574b19f8f436",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform='pandas')\n",
    "\n",
    "encoded_genres = ohe.fit_transform(df[['music_genre']])\n",
    "\n",
    "df = pd.concat([df, encoded_genres], axis=1).drop(columns=['music_genre'])\n",
    "df"
   ],
   "id": "248fe583bf2bd8a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Heatmap",
   "id": "249459fcc8cc03e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical = df.select_dtypes(exclude=object)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(numerical.corr(), annot=True, cmap=\"Greens\", fmt=\".2f\")"
   ],
   "id": "16a0fb5d2bcd5a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for col in numerical:\n",
    "    for col1 in numerical:\n",
    "        if col is col1:\n",
    "            continue\n",
    "\n",
    "        if abs(numerical[col].corr(numerical[col1])) >= 0.2:\n",
    "            plt.figure(figsize=(15,8))\n",
    "            sns.regplot(x=col,y=col1,data=numerical, line_kws={\"color\": \"Black\"})\n",
    "            plt.title(f\"{col} x {col1} Correlation: {round(numerical[col].corr(numerical[col1]),2)}\")\n",
    "            plt.show()"
   ],
   "id": "53ed6d326a9bca29",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
